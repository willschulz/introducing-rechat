---
title: "Introducing ReChat: Study 2"
author: "Will Schulz"
date: "2023-04-21"
output: html_document
---

```{r}
library(tidyverse)
library(stargazer)
library(rechat)
library(sandwich)
library(lmtest)
```


```{r}
single_row = T
```


```{r}
resizebox.stargazer = function(..., tab.width = "!", tab.height = "!"
                               ){
  input_list <- as.list(substitute(list(...)))
  #message(input_list$out)
  #Activate str_which() function:
  require(stringr) 

  #Extract the code returned from stargazer()
  res = capture.output(
    stargazer::stargazer(...)
    )

  #Render the arguments:
  tab.width = tab.width
  tab.height = tab.height

  #Attach "}" between \end{tabular} and \end{table}
  res = 
    prepend(res, "}", before = length(res))

  #Input \resizebox before \begin{tabular}
  res = 
    c(res[1:str_which(res, "^\\\\begin\\{tabular\\}.*")-1],
      paste0("\\resizebox{",tab.width,"}{",tab.height,"}{%"),
      #paste0("\\scalebox{",tab.width,"}{",tab.height,"}{%"),
      res[str_which(res, "^\\\\begin\\{tabular\\}.*"):length(res)]
      )

  #Produce the whole strings
  #cat(res, sep = "\n")
  cat(res, sep = "\n", file = input_list$out)
}


```

# Load Survey Data

```{r}
raw_survey_data <- readRDS(file = "data/study_2/raw_survey_data.rds")
```


# Load Chat Data and Parse

```{r eval = T}
chat_data <- parseChat("data/study_2/dem_chats_asof_220601.csv")
chat_data_republicans <- parseChat("data/study_2/rep_chats_asof_220601.csv")
```


# Drop Tests

```{r eval = T}
chat_data <- chat_data[-(1:4)]# chats 1:4 are tests
chat_data <- c(chat_data, chat_data_republicans)
```


## Study 2 Analyses

```{r, include = F}
make_robust_se <- function(mod){
  cov1         <- vcovCL(mod, cluster = ~room_id)
  robust_se    <- sqrt(diag(cov1))
  return(robust_se)
}
```


```{r include = F}
#clean chats
empty <- c()
for(i in 1:length(chat_data)){
  empty[i] <- nrow(chat_data[[i]]$messages)==0
}
if (any(empty)){chat_data <- chat_data[-which(empty)]}

#drop 1-person chats
single <- c()
for(i in 1:length(chat_data)){
  single[i] <- chat_data[[i]]$messages %>% pull(participantCode) %>% {length(unique(.))<2}
}
if (any(single)){chat_data <- chat_data[-which(single)]}

length(chat_data)
length(chat_data)*2
length(chat_data)*2/nrow(raw_survey_data %>% filter(Finished))

#drop few-message chats
min_mess <- c()
for(i in 1:length(chat_data)){
  min_mess[i] <- chat_data[[i]]$messages %>% group_by(participantCode) %>% summarise(mess_counts = length(message)) %>% pull(mess_counts) %>% {min(.)}
}
if (any(min_mess<2)){chat_data <- chat_data[-which(min_mess<2)]}
```


```{r include = F}
news_recode <- function(x){
  return(case_when(x == "Never" ~ 0,
          x == "Less often" ~ 1,
          x == "1-2 days a week" ~ 2,
          x == "3-6 days a week" ~ 3,
          x == "About once a day" ~ 4,
          x == "Several times a day" ~ 5))
}
```


```{r include = F}
s2_survey_data <- raw_survey_data %>%
  rename(ego_code = number_entry
  ) %>%
  mutate(
         chat_consent = case_when((chat_consent=="No, I do not want to participate") ~ FALSE,
                                  (chat_consent=="Yes, I want to participate") ~ TRUE),
         affpol_pre = case_when(partisanship == "Democrat" ~ thermo_pre_4 - thermo_pre_7,
                                partisanship == "Republican" ~ thermo_pre_7 - thermo_pre_4),
         affpol_post = case_when(partisanship == "Democrat" ~ thermo_post_4 - thermo_post_7,
                                partisanship == "Republican" ~ thermo_post_7 - thermo_post_4),
         affpol_change = affpol_post - affpol_pre,
         demthermo_change = thermo_post_4 - thermo_pre_4,
         repthermo_change = thermo_post_7 - thermo_pre_7,
         PID_5 = case_when(
               PID_dem_strength == "Strong" ~ -2,
               PID_dem_strength == "Not very strong" ~ -1,
               PID_leaners == "Closer to Democratic Party" ~ 0,
               PID_leaners == "Closer to Republican Party" ~ 0,
               PID_rep_strength == "Not very strong" ~ 1,
               PID_rep_strength == "Strong" ~ 2
               ),
         PID_6 = case_when(
               PID_dem_strength == "Strong" ~ 1,
               PID_dem_strength == "Not very strong" ~ 2,
               PID_leaners == "Closer to Democratic Party" ~ 3,
               PID_leaners == "Closer to Republican Party" ~ 4,
               PID_rep_strength == "Not very strong" ~ 5,
               PID_rep_strength == "Strong" ~ 6
               ),
         
         id_important = case_when(
               huddy1 =="Not important at all" ~ 0,
               huddy1 =="Not very important" ~ 1,
               huddy1 =="Very important" ~ 2,
               huddy1 =="Extremely important" ~ 3
               ),
             id_describe = case_when(
               huddy2 =="Not at all" ~ 0,
               huddy2 =="Not very well" ~ 1,
               huddy2 =="Very well" ~ 2,
               huddy2 =="Extremely well" ~ 3
               ),
             id_wethey = case_when(
               huddy3 =="Never" ~ 0,
               huddy3 =="Rarely" ~ 1,
               huddy3 =="Some of the time" ~ 2,
               huddy3 =="Most of the time" ~ 3,
               huddy3 =="All of the time" ~ 4
               ),
         
         tv = news_recode(news_media_1),
             newspapers = news_recode(news_media_2),
             radio = news_recode(news_media_3),
             internet_sm = news_recode(news_media_4),
             discussions = news_recode(news_media_5),
             podcasts = news_recode(news_media_6),
             
             twitter = !is.na(social_media_1),
             facebook = !is.na(social_media_2),
             instagram = !is.na(social_media_3),
             reddit = !is.na(social_media_9),
             tiktok = !is.na(social_media_10),
             youtube = !is.na(social_media_11),
             
             primary_sm = primary_sm,
         
         age = (2021 - birthyr),
             
             gender = pewmethods::fct_case_when(
               gender == "Female" ~ "Female",
               gender == "Male" ~ "Male",
               gender == "Other (please specify):" ~ "Other"
             ),
         
         male = (gender=="Male"),
             
             education = education,
         college = as.numeric(education)>=4,
         
         expressor = !(primary_sm %in% c("I don't use any of these services to express my opinions", NA)),
         
         sm_postpol_num = as.numeric(sm_postpol),
         
         ideo_7 = as.numeric(ideology)
         ) %>% filter(ideo_7<=4)

s2_survey_data$guess_partner_ideo <- as.numeric(s2_survey_data$guess_partner_ideo)
s2_survey_data$guess_partner_ideo[which(s2_survey_data$guess_partner_ideo==8)] <- NA

s2_survey_data$enjoyment <- as.numeric(s2_survey_data$enjoyment)
s2_survey_data$enjoyment[which(s2_survey_data$enjoyment==5)] <- NA
s2_survey_data$enjoyment <- max(s2_survey_data$enjoyment, na.rm = T)-s2_survey_data$enjoyment

s2_survey_data$sm_postpol_num[which(s2_survey_data$sm_postpol_num == 6)] <- NA
s2_survey_data$sm_postpol_num_nazero <- s2_survey_data$sm_postpol_num
s2_survey_data$sm_postpol_num_nazero[which(is.na(s2_survey_data$sm_postpol_num_nazero))] <- 0

#thermo_pre_4 is Democrats
#thermo_pre_7 is Republicans
s2_survey_data <- s2_survey_data %>% filter(partisanship!="Republican") #drop all republicans
```


```{r include = F}
#recode agree-disagree scales
ag_disag_recode <- function(x){
  return(case_when(x == "Strongly disagree" ~ 0,
          x == "Disagree" ~ 1,
          x == "Neither agree nor disagree" ~ 2,
          x == "Agree" ~ 3,
          x == "Strongly agree" ~ 4))
}

extro_cols <- s2_survey_data %>% select(ends_with("_extroversion"))
extro_cols <- apply(extro_cols, MARGIN = 2, ag_disag_recode)

# do pca
extroversion_scale <- psych::principal(extro_cols, nfactors = 1, rotate = "varimax", missing=TRUE, impute = "mean")$scores[,1]

if (cor(extroversion_scale, extro_cols[,5], use = "complete.obs")<0) {
  extroversion_scale <- (-extroversion_scale)
}
s2_survey_data$extroversion_scale <- extroversion_scale
```


```{r include = F}
#identity
identity_scale <- psych::principal(s2_survey_data %>% dplyr::select(starts_with("id_")), 
                              nfactors = 1, rotate = "varimax", missing=TRUE, impute = "mean")$scores[,1]

if (cor(identity_scale, s2_survey_data$id_important)<0) {
  identity_scale <- (-identity_scale)
}
s2_survey_data$identity_scale <- identity_scale
```


```{r include = F}
## Make SM Scale
sm_scale <- psych::principal(s2_survey_data %>% dplyr::select(twitter, facebook, instagram, reddit, tiktok, youtube),
                              nfactors = 1, rotate = "varimax", missing=TRUE, impute = "mean")$scores[,1]
s2_survey_data$sm_scale <- sm_scale
```


```{r include = F}
## Media Scale
media_scale <- psych::principal(s2_survey_data %>% dplyr::select(tv, newspapers, radio, internet_sm, discussions, podcasts),
                              nfactors = 1, rotate = "varimax", missing=TRUE, impute = "mean")$scores[,1]
s2_survey_data$media_scale <- media_scale
```


```{r include = F}
## self_mon Scale
selfmon_scale <- psych::principal(s2_survey_data %>% transmute(as.numeric(selfMon1), as.numeric(selfMon2), as.numeric(selfMon3)),
                              nfactors = 1, rotate = "varimax", missing=TRUE, impute = "mean")$scores[,1]

if(cor(selfmon_scale, as.numeric(s2_survey_data$selfMon2))>0){selfmon_scale <- (-selfmon_scale)}
s2_survey_data$selfmon_scale <- selfmon_scale
```


```{r include = F}
#combine extro and selfmon
extroselfmon_scale <- psych::principal(cbind(extro_cols, s2_survey_data %>% transmute(as.numeric(selfMon1), as.numeric(selfMon2), as.numeric(selfMon3))),
                              nfactors = 1, rotate = "varimax", missing=TRUE, impute = "mean")$scores[,1]

if (cor(extroselfmon_scale, extro_cols[,5], use = "complete.obs")<0) {
  extroselfmon_scale <- (-extroselfmon_scale)
}
s2_survey_data$extroselfmon_scale <- extroselfmon_scale
```



### Calculate Thoroughness (with package functions)


```{r}
word_counter <- function(message){
  return(str_count(message, "\\w+"))
}

chat_data <- featurizeChat(chat_data, featurization_function = nchar)
chat_data <- featurizeChat(chat_data, featurization_function = word_counter)

s2_survey_data <- summarizeChat(s2_survey_data, chat_data, chat_feature_name = "nchar", summary_function = sum, na.rm = T, summary_feature_name = "char_count")
s2_survey_data <- summarizeChat(s2_survey_data, chat_data, chat_feature_name = "word_counter", summary_function = sum, na.rm = T, summary_feature_name = "word_count")
```


```{r}
#add some more loquaciousness metrics
more_thoroughness <- function(chat){
  #link from participant codd to color code
  out <- chat$messages %>%
    group_by(participantCode) %>%
    summarize(message_count = length(message),
              unique_word_count = length(unique(unlist(strsplit(message, " ")))),
              median_word_length = median(nchar(unlist(strsplit(message, " ")))),
              mean_word_length = mean(nchar(unlist(strsplit(message, " "))))
              )
  out <- chat$participants %>% select(receiptCode, colorCode) %>% left_join(., out, by = c("colorCode" = "participantCode"))
  out <- out %>% mutate(room_id = chat$room_id, started_at = chat$started_at + 12*60*60) #manually adjust for 24-hour format
  return(out)
}

more_thoroughnesses <- function(chats, simplify = TRUE){
  out <- lapply(chats, more_thoroughness)
  if (simplify) {out <- data.table::rbindlist(l = out)}
  return(out)
}

#implement it

more_thoroughnesses <- more_thoroughnesses(chat_data)

#more_thoroughnesses

s2_survey_data <- left_join(s2_survey_data %>% filter(!is.na(ego_code)), more_thoroughnesses %>% filter(!is.na(receiptCode)) %>% select(-c("colorCode", "started_at")), by = c("ego_code" = "receiptCode"))

#s2_survey_data
```




### Match to Alters

```{r}
s2_survey_data <- matchAlters(s2_survey_data, chat_data)
s2_survey_data <- getAlterVars(s2_survey_data, var_names = c("t", "ideo_7", "affpol_pre", "identity_scale", "male", "PID_6", "message_count", "char_count"))
```


## DV: Thoroughness/Extent of Participation


```{r}
p3_prereg_base <- lm(char_count ~ t + ideo_7 + male, data = s2_survey_data %>% filter(!is.na(room_id)))
p3_prereg_mcount <- lm(message_count ~ t + ideo_7 + male, data = s2_survey_data %>% filter(!is.na(room_id)))
p3_prereg_wcount <- lm(word_count ~ t + ideo_7 + male, data = s2_survey_data %>% filter(!is.na(room_id)))
p3_prereg_uwcount <- lm(unique_word_count ~ t + ideo_7 + male, data = s2_survey_data %>% filter(!is.na(room_id)))
```


```{r, results='asis'}
# stargazer::stargazer(p3_prereg_base, p3_prereg_mcount, p3_prereg_wcount, p3_prereg_uwcount, type = "latex",
#                      se = list(make_robust_se(p3_prereg_base),make_robust_se(p3_prereg_mcount),make_robust_se(p3_prereg_wcount),make_robust_se(p3_prereg_uwcount)), label = "tab:s2_prereg_loquaciousness", title = "Loquaciousness (Study 2)", out = "outputs/s2_prereg_loquaciousness.tex", table.placement = "H")

resizebox.stargazer(p3_prereg_base, p3_prereg_mcount, p3_prereg_wcount, p3_prereg_uwcount, type = "latex",
                     se = list(make_robust_se(p3_prereg_base),make_robust_se(p3_prereg_mcount),make_robust_se(p3_prereg_wcount),make_robust_se(p3_prereg_uwcount)), label = "tab:s2_prereg_loquaciousness", title = "Loquaciousness (Study 2)", out = "outputs/s2_prereg_loquaciousness.tex", table.placement = "H", tab.width = "\\textwidth", single.row = single_row)

```

### Coefplots

```{r}
# 2-gang coefplot
pdf(file = "outputs/s2_coefplot_2gang_charmess.pdf", width = 8, height = 4)
var_lab_cex = .8

#coefplot for pre-reg model
these_coefs <- summary(p3_prereg_base)$coefficients
these_ses <- make_robust_se(p3_prereg_base)

# vars <- match(c("(Intercept)", "t", "ideo_7", "maleTRUE"), rownames(these_coefs)) %>% rev
# clean_names <- c("Intercept", "Co-Partisan Accountability Treatment", "Ideology", "Male") %>% rev

vars <- match(c("t", "ideo_7", "maleTRUE"), rownames(these_coefs)) %>% rev
clean_names <- c("Co-Partisan Accountability Treatment", "Ideology", "Male") %>% rev

par(bty = "n", pty = "s", mfrow = c(1,2))
plot(x = these_coefs[vars,1], y = 1:length(vars), xlab = "Coefficient", yaxt = "n", ylab = "", type = "n",
     xlim = c(-150, 100),
     ylim = c(0,length(vars)+1),
     main = "Character Count")
abline(v = 0, lty = 3)
points(x = these_coefs[vars,1], y = 1:length(vars), pch = 16)
#segments(x0 = these_coefs[vars,1]-1.96*these_coefs[vars,2], x1 = these_coefs[vars,1]+1.96*these_coefs[vars,2], y0 = 1:length(vars))
segments(x0 = these_coefs[vars,1]-1.96*these_ses[vars], x1 = these_coefs[vars,1]+1.96*these_ses[vars], y0 = 1:length(vars))
par(xpd = T)
text(x = these_coefs[vars,1], y = 1:length(vars), labels = clean_names, pos = 3, cex = var_lab_cex)
par(xpd = F)

#coefplot for message-count model
these_coefs <- summary(p3_prereg_mcount)$coefficients
these_ses <- make_robust_se(p3_prereg_mcount)

# vars <- match(c("(Intercept)", "t", "ideo_7", "maleTRUE"), rownames(these_coefs)) %>% rev
# clean_names <- c("Intercept", "Co-Partisan Accountability Treatment", "Ideology", "Male") %>% rev

vars <- match(c("t", "ideo_7", "maleTRUE"), rownames(these_coefs)) %>% rev
clean_names <- c("Co-Partisan Accountability Treatment", "Ideology", "Male") %>% rev

#par(bty = "n", pty = "s")
plot(x = these_coefs[vars,1], y = 1:length(vars), xlab = "Coefficient", yaxt = "n", ylab = "", type = "n",
     xlim = c(-5, 3),
     ylim = c(0,length(vars)+1),
     main = "Message Count")
abline(v = 0, lty = 3)
points(x = these_coefs[vars,1], y = 1:length(vars), pch = 16)
#segments(x0 = these_coefs[vars,1]-1.96*these_coefs[vars,2], x1 = these_coefs[vars,1]+1.96*these_coefs[vars,2], y0 = 1:length(vars))
segments(x0 = these_coefs[vars,1]-1.96*these_ses[vars], x1 = these_coefs[vars,1]+1.96*these_ses[vars], y0 = 1:length(vars))
par(xpd = T)
text(x = these_coefs[vars,1], y = 1:length(vars), labels = clean_names, pos = 3, cex = var_lab_cex)
par(xpd = F)
dev.off()
```


## DV: Affective Polarization

```{r}
#did attitudes get significantly more polarized?
affpol_data <- s2_survey_data %>% filter(chat_consent) %>% filter(!is.na(affpol_pre) & !is.na(affpol_post))

t.test(affpol_data$affpol_post, affpol_data$affpol_pre, paired = TRUE, alternative = "two.sided")

mean(affpol_data$affpol_change) #keep this, it's in the paper
```


```{r}
#did attitudes get significantly more polarized?
affpol_data <- s2_survey_data %>% filter(chat_consent) %>% filter(!is.na(affpol_pre) & !is.na(affpol_post))

affpol_data <- affpol_data %>% mutate(message_diff = (alter_message_count - message_count), char_diff = (alter_char_count - char_count)) %>% mutate(message_diff_bin = as.numeric(message_diff>0), char_diff_bin = as.numeric(char_diff>0))

t.test(affpol_data$affpol_post, affpol_data$affpol_pre, paired = TRUE, alternative = "two.sided")

mean(affpol_data$affpol_change)

#affpol_data$alter_message_count
#affpol_data$message_count

#affpol_data$alter_char_count
#affpol_data$char_count
```



```{r}
lm_affpol_0 <- lm(affpol_post ~ affpol_pre, data = affpol_data %>% filter(!is.na(room_id)))
lm_affpol_1 <- lm(affpol_post ~ affpol_pre + alter_affpol_pre, data = affpol_data %>% filter(!is.na(room_id)))
lm_affpol_1a <- lm(affpol_post ~ affpol_pre + alter_affpol_pre*message_diff_bin, data = affpol_data %>% filter(!is.na(room_id)))
lm_affpol_1b <- lm(affpol_post ~ affpol_pre + alter_affpol_pre*char_diff_bin, data = affpol_data %>% filter(!is.na(room_id)))
lm_affpol_2 <- lm(affpol_post ~ affpol_pre + alter_affpol_pre + t, data = affpol_data %>% filter(!is.na(room_id)))

stargazer(lm_affpol_0,lm_affpol_1,lm_affpol_2, type = "latex",
          se = list(make_robust_se(lm_affpol_0), make_robust_se(lm_affpol_1), make_robust_se(lm_affpol_2)), title = "Group Polarization", label = "tab:s2_group_polarization_main", out = "outputs/s2_group_polarization_main.tex", dep.var.labels = "Post-Chat Partisan Affect (D - R Feeling Thermo Diff)", covariate.labels = c("Pre-Chat Affect", "Partner's Pre-Chat Affect", "Treatment\\\\(Co-Partisan Accountability)"), omit.stat = c("f"), table.placement = "H", single.row = single_row)

stargazer(lm_affpol_1a,lm_affpol_1b, type = "latex",
         se = list(make_robust_se(lm_affpol_1a), make_robust_se(lm_affpol_1b)), title = "Group Polarization (Interaction Tests of Relative Loquaciousness)", label = "tab:s2_group_polarization_interactions", omit.stat = c("f"), out = "outputs/s2_group_polarization_interactions.tex", table.placement = "H", single.row = single_row)

```


